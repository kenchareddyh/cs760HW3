{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "68e1da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b70d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3000) (5000,)\n"
     ]
    }
   ],
   "source": [
    "trainset = pd.read_csv('data/emails.csv')\n",
    "traindata = np.loadtxt('data/emails.csv',delimiter=',', skiprows=1, usecols=range(1,3002))\n",
    "EX_train = traindata[:, :3000]  \n",
    "Ey_train = traindata[:,3000]\n",
    "\n",
    "print(EX_train.shape, Ey_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "023908f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    \"\"\"\n",
    "    Sigmoid function\n",
    "    \"\"\"\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "\n",
    "def calc_gradient(X, y, y_hat, m):\n",
    "    \"\"\"\n",
    "    Calculate gradient\n",
    "    \"\"\"\n",
    "    grad = (1/m)*np.dot(X.T, (y_hat - y))   \n",
    "    return grad\n",
    "\n",
    "\n",
    "def cost_func(y, y_hat, m):\n",
    "    \"\"\"\n",
    "    Calculate cross entroy loss\n",
    "    \"\"\"\n",
    "    cost = (-1/m) * np.sum((y * np.log(y_hat)) + (1 - y) * np.log(1 - y_hat))\n",
    "    return cost\n",
    "\n",
    "def fit_log_reg(X, y, itr, lr):\n",
    "    \"\"\"\n",
    "    Train log reg function\n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    theta = np.zeros((n,1))\n",
    "    cost_list = []\n",
    "    \n",
    "    for i in range(itr):\n",
    "        y_hat = sig(np.dot(X, theta))\n",
    "        grad = calc_gradient(X, y, y_hat, m)\n",
    "        \n",
    "        theta = theta - (lr * grad)\n",
    "        cost = cost_func(y, sig(np.dot(X, theta)), m)\n",
    "        cost_list.append(cost)\n",
    "    return theta, cost_list\n",
    "        \n",
    "def predict(X, theta):\n",
    "    \"\"\"\n",
    "    Return predictions list\n",
    "    \"\"\"\n",
    "    predictions = sigmoid(np.dot(X, theta))\n",
    "    labels = []\n",
    "              \n",
    "    for pred in predictions:\n",
    "        if pred >= 0.5:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "            \n",
    "    labels = np.asarray(labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d450e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "44eb69ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0\n",
      "(1000, 3000) (1000,) (4000, 3000) (4000,)\n",
      "Accuracy = 0.915 TP = 229 TN = 686 FP = 29 FN = 56\n",
      "Precision = 0.8875968992248062 Recall = 0.8035087719298246\n",
      "FOLD: 1\n",
      "(1000, 3000) (1000,) (4000, 3000) (4000,)\n",
      "Accuracy = 0.893 TP = 214 TN = 679 FP = 44 FN = 63\n",
      "Precision = 0.8294573643410853 Recall = 0.7725631768953068\n",
      "FOLD: 2\n",
      "(1000, 3000) (1000,) (4000, 3000) (4000,)\n",
      "Accuracy = 0.888 TP = 221 TN = 667 FP = 49 FN = 63\n",
      "Precision = 0.8185185185185185 Recall = 0.778169014084507\n",
      "FOLD: 3\n",
      "(1000, 3000) (1000,) (4000, 3000) (4000,)\n",
      "Accuracy = 0.834 TP = 139 TN = 695 FP = 11 FN = 155\n",
      "Precision = 0.9266666666666666 Recall = 0.47278911564625853\n",
      "FOLD: 4\n",
      "(1000, 3000) (1000,) (4000, 3000) (4000,)\n",
      "Accuracy = 0.851 TP = 213 TN = 638 FP = 56 FN = 93\n",
      "Precision = 0.79182156133829 Recall = 0.696078431372549\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"FOLD: \" + str(i))\n",
    "    X_test  = EX_train[i*1000:(i+1)*1000]\n",
    "    y_test  = Ey_train[i*1000:(i+1)*1000] \n",
    "    indices = np.arange(i*1000, (i+1)*1000, 1, dtype=int)\n",
    "    X_train = np.delete(EX_train, indices, axis=0)\n",
    "    y_train = np.delete(Ey_train, indices, axis=0)\n",
    "    print(X_test.shape, y_test.shape, X_train.shape, y_train.shape)\n",
    "    \n",
    "    # initialize the classifier with value of number of neighbors=1\n",
    "    theta,cost_list = train(X_train, y_train, 1000, 0.01)\n",
    "    # Make predictions\n",
    "    predictions = predict(X_test, theta)\n",
    "    accuracy = np.sum(predictions == y_test)/(len(y_test))\n",
    "    TP = np.sum(np.logical_and(predictions == 1, y_test == 1))\n",
    "    TN = np.sum(np.logical_and(predictions == 0, y_test == 0))\n",
    "    FP = np.sum(np.logical_and(predictions == 1, y_test == 0))\n",
    "    FN = np.sum(np.logical_and(predictions == 0, y_test == 1))\n",
    "    print (\"Accuracy = \" + str(accuracy))\n",
    "    print (\"Precision = \" + str (float (TP/(TP+FP))), \"Recall = \" + str (float(TP/(TP+FN))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d281a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
